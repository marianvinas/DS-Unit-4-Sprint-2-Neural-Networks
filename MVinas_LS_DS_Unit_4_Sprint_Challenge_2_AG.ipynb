{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "MVinas_LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0WgRWXN_SK7"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZOMoLAt_SK9"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2d017ba3200be3890c0b67eda283c48",
          "grade": false,
          "grade_id": "cell-621a8b86bacf295a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "NIavTNUD_SK-"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:**\n",
        "\n",
        "- **Input Layer:** \n",
        "\n",
        "- **Hidden Layer:** \n",
        "\n",
        "- **Output Layer:**\n",
        "\n",
        "- **Activation:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7233c31461609b21a7fc2651afb12632",
          "grade": true,
          "grade_id": "cell-6adae65226f09553",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "pmfedbDx_SK_"
      },
      "source": [
        "YOUR ANSWER HERE  \n",
        "**Neuron** = or artificial neuron, it is a layer which mathematically transform the data, also referred to as a perceptron.   \n",
        "**Input Layer** = the beginning of the artificial neural network in the workflow.   \n",
        "**Hidden Layer** = this is the layer between input and output layers.   \n",
        "**Output Layer** = is the last layer that produces given outputs.    \n",
        "**Activation** = used to determine the output and it maps the resulting values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bb49a3d32ff92032e5bc641764d86ca4",
          "grade": false,
          "grade_id": "cell-d64f1de9e9458dc7",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "aJW4yXxk_SLA"
      },
      "source": [
        "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
          "grade": true,
          "grade_id": "cell-cef20b23d4e0b056",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3j39c3cV_SLA"
      },
      "source": [
        "**YOUR ANSWER HERE**    \n",
        "Back propagation is a process used to learn error function, this method calculates of the error function with respect to the neural network's weights. This is a backward flow of the error information allows for efficient computation at each layer versus calculating each layer separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f57b11b197b768f69957260035113f43",
          "grade": false,
          "grade_id": "cell-e013d19857352d79",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "X2pFKoeH_SLA"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d746de6391012340f8548821850a621c",
          "grade": true,
          "grade_id": "cell-53c7cc36db9d7983",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "OWOoxMoW_SLB"
      },
      "source": [
        "**YOUR ANSWER HERE**   \n",
        "Start with values (often random) for the network parameters (weights and biases). Take a set of examples of input data and pass them through the network to obtain their prediction. Compare these predictions obtained with the values of expected labels and calculate the loss with them. Perform the backpropagation in order to propagate this loss to each and every one of the parameters that make up the model of the neural network. Use this propagated information to update the parameters of the neural network with the gradient descent in a way that the total loss is reduced and a better model is obtained. Continue iterating in the previous steps until we consider that we have a good model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrXLTMuJ_SLB"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TiX8_q_SLB"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bxAAEjU_SLB"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "You model should have `1 dense layer` with a `single neuron` and a `sigmoid activation function`. \n",
        "\n",
        "\n",
        "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ed5db44c2ae01d03f766beeeca1a7f0a",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re1_52hp_SLC",
        "outputId": "5f9fdf51-991b-467a-9e49-b9e18149bc93"
      },
      "source": [
        "#import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(units=1, input_dim=2, activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "h1 = model1.fit(X, y, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 1ms/step - loss: 0.9921 - accuracy: 0.4414\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 1.0025 - accuracy: 0.4305\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 1.0167 - accuracy: 0.4299\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 1.0158 - accuracy: 0.4420\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 1.0048 - accuracy: 0.4183\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.9697 - accuracy: 0.4618\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9996 - accuracy: 0.4384\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.9891 - accuracy: 0.4374\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.9713 - accuracy: 0.4325\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.9344 - accuracy: 0.4821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "mIXPX0pu_SLC"
      },
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
        "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7W55GCnCRRq",
        "outputId": "a79bdc32-2f09-435e-b1d6-0ea0fba004e8"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model1.evaluate(X, y)\n",
        "print(f\"{model1.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 0.9580 - accuracy: 0.4500\n",
            "accuracy: 44.999998807907104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "NxTEnRXO_SLC"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tGQ-ErQ_SLC"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron using. Here are some architecture suggestions: \n",
        "- `2` Hidden Layers\n",
        "- `5-32` Neurons in the Hidden Layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `Callback function` below into your model\n",
        "- Set epochs to `100`\n",
        "\n",
        "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfJY8KWE_SLD"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > .99999):   \n",
        "            self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGFzJA_-_SLD",
        "outputId": "93d9a33a-4838-4399-afd1-a7b7ba69d5c3"
      },
      "source": [
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.layers import ReLU\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "callbks = myCallback()\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    Dense(5, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "\n",
        "h2 = model2.fit(X, y, epochs=100, \n",
        "         callbacks = callbks\n",
        ")          \n",
        "\n",
        "#model1 = Sequential()\n",
        "#model1.add(Dense(units=1, input_dim=2, activation='sigmoid'))\n",
        "#model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#h1 = model1.fit(X, y, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 0.6898 - accuracy: 0.4909\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.4730\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.6683 - accuracy: 0.5683\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.7450\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.8211\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.8521\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.8721\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.9014\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.8755\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.9125\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.8794\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8950\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8948\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.9094\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.9044\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.9234\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.9201\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.9420\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.9140\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.9289\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.9490\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.9578\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.9534\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.9634\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.9551\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.9468\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.9641\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.9715\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.9569\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.9453\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.9430\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.9642\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9710\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9717\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9582\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9793\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9710\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9816\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9646\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9570\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9752\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9685\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9845\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9795\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9781\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9834\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9616\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9782\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9775\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9798\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9828\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9813\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9732\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9841\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9815\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9759\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9855\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9684\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9724\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9867\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9902\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9931\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9903\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9867\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9854\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9817\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9908\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9908\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9819\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9865\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9889\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9870\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9934\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9838\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9867\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9861\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9900\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9957\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9945\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9953\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9994\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "612b9128f3a57d18c3019b2a12ace3c8",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eH-kX1pC_SLD"
      },
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\"\n",
        "\n",
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNYKWjss_SLD"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIZnyfKMHMzh",
        "outputId": "069a0b25-0012-436a-9e77-25f7f3236926"
      },
      "source": [
        "! pip install mlxtend"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (53.0.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "a_MWNvKz_SLD",
        "outputId": "ed02dbb3-1cef-4516-c56d-4da3270d96e9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "dfefeea12a0993da5cf2b70ee858f890",
          "grade": false,
          "grade_id": "cell-b1bde9222e35b3fc",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "WY6V2-ga_SLE"
      },
      "source": [
        "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
        "\n",
        "Why might this property be useful in more complex data such as images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
          "grade": true,
          "grade_id": "cell-302694c508c8da0e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "DhaY_zBd_SLE"
      },
      "source": [
        "\n",
        "\n",
        "**YOUR ANSWER HERE**\n",
        "\n",
        "The Perceptron (model1) only achieve ~70% accuracy because it can only take few inputs, each of which has to signify how important it is and generate an output decision of 0 or 1. The architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y is backpropagation, so the difference between the current output and signal is used to adjust the output layer and then used to adjust hidden layers and going back through the network towards the inputs. the resulting error is propagated back from the output to the input of the network to adjust it.\n",
        "\n",
        "Backpropagation is useful for deep neural networks working on error-prone projects as image because it allows you to reduce error rates and to make the model reliable by increasing it generalization. It helps to calculate the gradient of a liss function with respects to all the weights in the network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMR2kMJy_SLE"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyperparameter tune two parameters each with no more than 3 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyperparameter tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "ZI63vTvm_SLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e597c18b-e5f8-43e7-f38e-47999cc34942"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>282</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>289</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>112</td>\n",
              "      <td>268</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>150</td>\n",
              "      <td>283</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "75    55    0   1       135   250    0  ...      0      1.4      1   0     2       1\n",
              "193   60    1   0       145   282    0  ...      1      2.8      1   2     3       0\n",
              "232   55    1   0       160   289    0  ...      1      0.8      1   1     3       0\n",
              "122   41    0   2       112   268    0  ...      1      0.0      2   0     2       1\n",
              "14    58    0   3       150   283    1  ...      0      1.0      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xW4Q3xj0_SLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df3aaf5-b68a-4652-896d-ace94b88c35d"
      },
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "\n",
        "# YOUR CODE HERE\n",
        "import tensorflow as tf\n",
        "import numpy\n",
        "from tensorflow import keras\n",
        "from keras.utils import normalize\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam, Adagrad, SGD, Ftrl, RMSprop\n",
        "\n",
        "\n",
        "target = \"target\"\n",
        "features = [column for column in df.columns if column != \"target\"]\n",
        "\n",
        "Y = df[target].values\n",
        "X = df[features].values\n",
        "\n",
        "normal_X = normalize(X)\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(normal_X, Y, train_size= 0.8, test_size= 0.2)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(242, 13) (61, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKhIQjA7yosz",
        "outputId": "6423e386-d673-4e6a-b492-692a138858f4"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(32, activation= \"sigmoid\", input_shape= (13,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=100,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.2566 - accuracy: 0.3934 - val_loss: 0.2459 - val_accuracy: 0.6066\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2487 - accuracy: 0.5470 - val_loss: 0.2451 - val_accuracy: 0.6066\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2509 - accuracy: 0.5015 - val_loss: 0.2451 - val_accuracy: 0.6066\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2495 - accuracy: 0.5243 - val_loss: 0.2450 - val_accuracy: 0.6066\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2490 - accuracy: 0.5325 - val_loss: 0.2443 - val_accuracy: 0.6066\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5145 - val_loss: 0.2446 - val_accuracy: 0.6066\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2475 - accuracy: 0.5584 - val_loss: 0.2443 - val_accuracy: 0.6066\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2482 - accuracy: 0.5453 - val_loss: 0.2451 - val_accuracy: 0.6066\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.5295 - val_loss: 0.2470 - val_accuracy: 0.6066\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2490 - accuracy: 0.5375 - val_loss: 0.2460 - val_accuracy: 0.6066\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2483 - accuracy: 0.5506 - val_loss: 0.2442 - val_accuracy: 0.6066\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2491 - accuracy: 0.5277 - val_loss: 0.2435 - val_accuracy: 0.6066\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2486 - accuracy: 0.5355 - val_loss: 0.2442 - val_accuracy: 0.6066\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.5529 - val_loss: 0.2441 - val_accuracy: 0.6066\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5126 - val_loss: 0.2442 - val_accuracy: 0.6066\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2489 - accuracy: 0.5279 - val_loss: 0.2445 - val_accuracy: 0.6066\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2481 - accuracy: 0.5459 - val_loss: 0.2445 - val_accuracy: 0.6066\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2493 - accuracy: 0.5193 - val_loss: 0.2453 - val_accuracy: 0.6066\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.5065 - val_loss: 0.2443 - val_accuracy: 0.6066\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.5328 - val_loss: 0.2434 - val_accuracy: 0.6066\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2526 - accuracy: 0.4773 - val_loss: 0.2443 - val_accuracy: 0.6066\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2476 - accuracy: 0.5475 - val_loss: 0.2430 - val_accuracy: 0.6066\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2489 - accuracy: 0.5246 - val_loss: 0.2433 - val_accuracy: 0.6066\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2489 - accuracy: 0.5232 - val_loss: 0.2442 - val_accuracy: 0.6066\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2454 - accuracy: 0.5847 - val_loss: 0.2426 - val_accuracy: 0.6066\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.5368 - val_loss: 0.2448 - val_accuracy: 0.6066\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.2513 - accuracy: 0.4799 - val_loss: 0.2475 - val_accuracy: 0.6066\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2478 - accuracy: 0.5727 - val_loss: 0.2444 - val_accuracy: 0.6066\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2509 - accuracy: 0.4814 - val_loss: 0.2458 - val_accuracy: 0.6066\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.5022 - val_loss: 0.2439 - val_accuracy: 0.6066\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2469 - accuracy: 0.5501 - val_loss: 0.2416 - val_accuracy: 0.6066\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.5113 - val_loss: 0.2433 - val_accuracy: 0.6066\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2481 - accuracy: 0.5254 - val_loss: 0.2433 - val_accuracy: 0.6066\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2463 - accuracy: 0.5537 - val_loss: 0.2434 - val_accuracy: 0.6066\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2477 - accuracy: 0.5307 - val_loss: 0.2443 - val_accuracy: 0.6066\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2472 - accuracy: 0.5373 - val_loss: 0.2429 - val_accuracy: 0.6066\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.4916 - val_loss: 0.2437 - val_accuracy: 0.6066\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2465 - accuracy: 0.5479 - val_loss: 0.2427 - val_accuracy: 0.6066\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2482 - accuracy: 0.5179 - val_loss: 0.2441 - val_accuracy: 0.6066\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2481 - accuracy: 0.5163 - val_loss: 0.2436 - val_accuracy: 0.6066\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2472 - accuracy: 0.5263 - val_loss: 0.2437 - val_accuracy: 0.6066\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2460 - accuracy: 0.5438 - val_loss: 0.2432 - val_accuracy: 0.6066\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2470 - accuracy: 0.5215 - val_loss: 0.2450 - val_accuracy: 0.6066\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2467 - accuracy: 0.5287 - val_loss: 0.2426 - val_accuracy: 0.6066\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2440 - accuracy: 0.5727 - val_loss: 0.2423 - val_accuracy: 0.6066\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2461 - accuracy: 0.5289 - val_loss: 0.2447 - val_accuracy: 0.6066\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2452 - accuracy: 0.5558 - val_loss: 0.2426 - val_accuracy: 0.6066\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.5081 - val_loss: 0.2437 - val_accuracy: 0.6066\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2453 - accuracy: 0.5368 - val_loss: 0.2432 - val_accuracy: 0.6066\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2466 - accuracy: 0.5152 - val_loss: 0.2433 - val_accuracy: 0.6066\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2445 - accuracy: 0.5459 - val_loss: 0.2420 - val_accuracy: 0.6066\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2450 - accuracy: 0.5255 - val_loss: 0.2434 - val_accuracy: 0.6066\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2423 - accuracy: 0.5643 - val_loss: 0.2423 - val_accuracy: 0.6066\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2460 - accuracy: 0.5205 - val_loss: 0.2440 - val_accuracy: 0.6066\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2451 - accuracy: 0.5189 - val_loss: 0.2417 - val_accuracy: 0.6066\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.5184 - val_loss: 0.2409 - val_accuracy: 0.6066\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.5238 - val_loss: 0.2414 - val_accuracy: 0.6066\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2457 - accuracy: 0.5245 - val_loss: 0.2427 - val_accuracy: 0.6066\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2418 - accuracy: 0.5685 - val_loss: 0.2396 - val_accuracy: 0.6066\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2419 - accuracy: 0.5602 - val_loss: 0.2439 - val_accuracy: 0.6066\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2414 - accuracy: 0.6141 - val_loss: 0.2424 - val_accuracy: 0.6393\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2411 - accuracy: 0.6075 - val_loss: 0.2416 - val_accuracy: 0.6230\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2416 - accuracy: 0.5583 - val_loss: 0.2384 - val_accuracy: 0.6066\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2434 - accuracy: 0.5227 - val_loss: 0.2405 - val_accuracy: 0.6230\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2378 - accuracy: 0.6104 - val_loss: 0.2394 - val_accuracy: 0.6230\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.6759 - val_loss: 0.2430 - val_accuracy: 0.6393\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2374 - accuracy: 0.6367 - val_loss: 0.2381 - val_accuracy: 0.6230\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2349 - accuracy: 0.6217 - val_loss: 0.2397 - val_accuracy: 0.6066\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2384 - accuracy: 0.6861 - val_loss: 0.2438 - val_accuracy: 0.6230\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2355 - accuracy: 0.7061 - val_loss: 0.2353 - val_accuracy: 0.6066\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2345 - accuracy: 0.5970 - val_loss: 0.2402 - val_accuracy: 0.6393\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2323 - accuracy: 0.7273 - val_loss: 0.2382 - val_accuracy: 0.6230\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.6235 - val_loss: 0.2356 - val_accuracy: 0.6066\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.6907 - val_loss: 0.2411 - val_accuracy: 0.6393\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2321 - accuracy: 0.6647 - val_loss: 0.2337 - val_accuracy: 0.6066\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2287 - accuracy: 0.6813 - val_loss: 0.2393 - val_accuracy: 0.6557\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.2287 - accuracy: 0.6950 - val_loss: 0.2376 - val_accuracy: 0.6557\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2286 - accuracy: 0.6738 - val_loss: 0.2323 - val_accuracy: 0.6066\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2254 - accuracy: 0.6836 - val_loss: 0.2368 - val_accuracy: 0.6557\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 0.6971 - val_loss: 0.2314 - val_accuracy: 0.6066\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2249 - accuracy: 0.6231 - val_loss: 0.2306 - val_accuracy: 0.6066\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2152 - accuracy: 0.7054 - val_loss: 0.2375 - val_accuracy: 0.6230\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2180 - accuracy: 0.7229 - val_loss: 0.2307 - val_accuracy: 0.6066\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2135 - accuracy: 0.7684 - val_loss: 0.2374 - val_accuracy: 0.6230\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2145 - accuracy: 0.7069 - val_loss: 0.2276 - val_accuracy: 0.6393\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2174 - accuracy: 0.6404 - val_loss: 0.2381 - val_accuracy: 0.6557\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2163 - accuracy: 0.6852 - val_loss: 0.2273 - val_accuracy: 0.6393\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2089 - accuracy: 0.7020 - val_loss: 0.2313 - val_accuracy: 0.6557\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2134 - accuracy: 0.6864 - val_loss: 0.2258 - val_accuracy: 0.6066\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2151 - accuracy: 0.6557 - val_loss: 0.2287 - val_accuracy: 0.6721\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2013 - accuracy: 0.7635 - val_loss: 0.2274 - val_accuracy: 0.6393\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2002 - accuracy: 0.7580 - val_loss: 0.2266 - val_accuracy: 0.6393\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2036 - accuracy: 0.7560 - val_loss: 0.2267 - val_accuracy: 0.6557\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2010 - accuracy: 0.7355 - val_loss: 0.2252 - val_accuracy: 0.6393\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1930 - accuracy: 0.7399 - val_loss: 0.2257 - val_accuracy: 0.6557\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2156 - accuracy: 0.6618 - val_loss: 0.2242 - val_accuracy: 0.6230\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2136 - accuracy: 0.6567 - val_loss: 0.2241 - val_accuracy: 0.6230\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2026 - accuracy: 0.6771 - val_loss: 0.2284 - val_accuracy: 0.6721\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2053 - accuracy: 0.6872 - val_loss: 0.2236 - val_accuracy: 0.6230\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1958 - accuracy: 0.7385 - val_loss: 0.2265 - val_accuracy: 0.6557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7J-fI_TI_SLG"
      },
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnaJbrzSwq2R",
        "outputId": "9aad36aa-3393-4f6b-b2bd-ff52068f3ede"
      },
      "source": [
        "X.shape[0] == 303"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hey0iobNwtis",
        "outputId": "7c75223d-88a3-4589-d01d-5a9479570943"
      },
      "source": [
        "X.shape[1] == 13"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2adpYlhzwv0o",
        "outputId": "5c0dceb2-9274-49ba-c036-dc34850eb2e7"
      },
      "source": [
        "len(Y)== 303"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhQiYji6_SLG"
      },
      "source": [
        "# Imports to add GridSearch and the classifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "JjhoLquX_SLG"
      },
      "source": [
        "# Create a function named 'create_model' that returns a complied keras model -  required for KerasClassifier\n",
        "# YOUR CODE HERE\n",
        "def create_model(units=32):\n",
        "    \n",
        "    # create model\n",
        "    model = tf.keras.Sequential([\n",
        "    Dense(32, activation= \"sigmoid\", input_shape= (13,)),\n",
        "    Dense(32, activation= \"relu\"),\n",
        "    Dense(16, activation= \"sigmoid\"),\n",
        "    Dense(8, activation= \"relu\")\n",
        "    ])\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW9NoMjT_SLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ef9262-795b-4577-ecd6-fd9d06c75f20"
      },
      "source": [
        "type(create_model())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.engine.sequential.Sequential"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UcYTPChC_SLH"
      },
      "source": [
        "# Visible Testing\n",
        "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "djTxq0zt_SLH"
      },
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0442c29a94065e922c5ae929976a52ab",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d1nI7BTv_SLH"
      },
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4WFjp_E7_V7",
        "outputId": "e0e9eb7c-f904-485e-80d0-a9e73cc3fc69"
      },
      "source": [
        "model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn',"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f522d3a9a4bb90f7231d1be98d067c62",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "h54E5kQr_SLH"
      },
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with no more than 3 possible values for each \n",
        "\n",
        "# YOUR CODE HERE\n",
        "param_grid = {'batch_size': [10, 20, 40], \n",
        "              'epochs': [20, 30, 50]}"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6y0H2uLC_SLH"
      },
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "0TElnTPV_SLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5ece14-0d69-4a5c-f5ab-d93f39eed6de"
      },
      "source": [
        "# Create Grid Search object and name it 'gs'\n",
        "# Run Grid Search \n",
        "# YOUR CODE HERE\n",
        "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "\n",
        "# report results\n",
        "grid_result = gs.fit(X_train, Y_train)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7.2463 - accuracy: 0.5707\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7.5350 - accuracy: 0.4817\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4669\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4352\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4665\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5018\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4959\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4641\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4572\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4913\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4941\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4788\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5053\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5043\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5027\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4799\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5003\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5010\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4609\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5250\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cab8dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4490\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 1s 1ms/step - loss: 7.9163 - accuracy: 0.5232\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6.4032 - accuracy: 0.5082\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.7438 - accuracy: 0.5185\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.4950\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5894\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5641\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5631\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5592\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5482\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5461\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.6209\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.7076\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.6799\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.7027\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.6414\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.6306\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5894\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.6428\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5793\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5725\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c780e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4082\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 15.9706 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 15.2802 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.4862 - accuracy: 0.1993 \n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4913\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4937\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5223\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4966\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4466\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4541\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4793\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4704\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4872\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4702\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4456\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4983\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4740\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4689\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4664\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5336\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4645\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4792\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 7.6686 - accuracy: 0.5298\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 7.2210 - accuracy: 0.4806\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.9632 - accuracy: 0.5546\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8384 - accuracy: 0.5659\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7910 - accuracy: 0.5772\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.8367 - accuracy: 0.5243\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.8395 - accuracy: 0.5050\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7957 - accuracy: 0.5295\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7816 - accuracy: 0.5305\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.7954 - accuracy: 0.5041\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7690 - accuracy: 0.5212\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7139 - accuracy: 0.5768\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7411 - accuracy: 0.5372\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7623 - accuracy: 0.5016\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.5290\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.7447 - accuracy: 0.5087\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.5434\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.5494\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.6025\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.5219\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.4792\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.5539 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7.6125 - accuracy: 0.5423\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 6.9347 - accuracy: 0.5431\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 4.8732 - accuracy: 0.4965\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4885\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4691\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4796\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5081\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4822\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4803\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4813\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4436\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5058\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4632\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4902\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4438\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4225\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4406\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4648\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.3939\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 1.1464 - accuracy: 0.1841\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7649 - accuracy: 0.4975\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5198\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4835\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5080\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.4985\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.4952\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5348\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5043\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5313\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5433\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5159\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5350\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5363\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5358\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4404\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5089\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.4601\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5258\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5105\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.4699\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5057\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.4946\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5431\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4719\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5301\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4991\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5286\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5041\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5135\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5510\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 8.8930 - accuracy: 0.4468\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6.9795 - accuracy: 0.5051\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4280\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4941\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4618\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4751\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5437\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4922\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4731\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5040\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5064\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4688\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4819\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5204\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4700\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5282\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4621\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4608\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4588\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5161\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5287\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5268\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4813\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5308\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4637\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4571\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4936\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5054\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4876\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5079\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.3878\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.0731 - accuracy: 0.3317\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 8.7368 - accuracy: 0.4712\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 8.6492 - accuracy: 0.4314\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.3530 - accuracy: 0.4246\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4756\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5263\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4394\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4759\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4556\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4812\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4939\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4506\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4953\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4144\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4738\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4805\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5423\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5220\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4443\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4986\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4561\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4901\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4731\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4248\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4910\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4559\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4288\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4819\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4764\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4467\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4792\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 14.7764 - accuracy: 0.0039\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.1030 - accuracy: 0.5119\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4621\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4551\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4553\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4612\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4380\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5043\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5064\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4379\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4725\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4154\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4602\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4870\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5181\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4357\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4851\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4206\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4322\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4526\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4177\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4146\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4331\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4787\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4218\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4316\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4206\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4751\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4886\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4438\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7.9768 - accuracy: 0.1875\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.0825 - accuracy: 0.5207\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 7.4175 - accuracy: 0.5312\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 4.4927 - accuracy: 0.5245\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0926 - accuracy: 0.4506\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4390\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4720\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4858\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4409\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4774\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4812\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5366\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4475\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4483\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4680\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4741\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4681\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4524\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4461\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4790\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4734\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4433\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4187\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4597\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5042\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4505\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4184\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5460\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4062\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4319\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 15.8568 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 14.8461 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6.1107 - accuracy: 0.5340\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7.5363 - accuracy: 0.4609\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7.3302 - accuracy: 0.4724\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 7.6292 - accuracy: 0.4402\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6.1434 - accuracy: 0.5172\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4537\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4637\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5015\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5050\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5067\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5061\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4209\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4605\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4768\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4718\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4387\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5056\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4787\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4966\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4668\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4870\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4331\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5008\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4786\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4611\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4581\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4900\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4805\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4707\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5201\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4603\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4786\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4589\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5347\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5004\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5243\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4361\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4641\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4703\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4408\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4444\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4756\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5074\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4703\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4672\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4779\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5141\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4849\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4490\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.4237 - accuracy: 0.0403\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.6837 - accuracy: 0.4808\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 6.9945 - accuracy: 0.5435\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 4.7880 - accuracy: 0.5262\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4874\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5112\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5146\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4926\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5025\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4795\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.5269\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5062\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5082\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4974\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5259\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5268\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4816\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5107\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4653\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4913\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5401\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5206\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4995\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4774\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4682\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4532\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4943\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5254\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4746\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5201\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4518\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5122\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5420\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4839\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4571\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5136\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5305\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4360\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5307\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4520\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4766\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5007\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4609\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4847\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4897\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4905\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4998\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5030\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4691\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5160\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.3878\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 1s 1ms/step - loss: 7.3450 - accuracy: 0.5471\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 5.6990 - accuracy: 0.5650\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4919\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4921\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4695\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4812\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4385\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4710\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4222\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4543\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4418\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4357\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5162\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4838\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4577\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4696\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5002\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4550\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5090\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5136\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4213\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4576\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4810\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5573\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4266\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4293\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4698\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5179\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4413\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4397\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5090\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4927\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4392\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4668\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4632\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4726\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 2.0794 - accuracy: 0.4713\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4334\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5190\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.3825\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4658\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5089\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4361\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5281\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4766\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4704\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4944\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4069\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4840\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5017\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4792\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.9957 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.0022 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.9565 - accuracy: 0.2344\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7.9452 - accuracy: 0.4517\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 5.3231 - accuracy: 0.4718\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4213\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5070\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5345\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4613\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4363\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4738\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4349\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4662\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4632\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4550\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4749\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4652\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4499\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5124\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4734\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4748\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4664\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4960\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4399\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4830\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4650\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4556\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5040\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4288\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4744\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4403\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4684\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4649\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4541\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4800\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.3883\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4515\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4241\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4172\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5018\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4779\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4719\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4881\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4421\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4644\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4785\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5048\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5211\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4753\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4776\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 14.6757 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.5433 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.8607 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.7882 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.5466 - accuracy: 0.0222 \n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.7136 - accuracy: 0.4304\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7604 - accuracy: 0.4790\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5354\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5681\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5240\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5114\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5276\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5764\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5175\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5501\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5124\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.6169\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5560\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5568\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5703\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5483\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5101\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5225\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5336\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5481\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5189\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5556\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5265\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5329\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5221\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5655\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5100\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5593\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.4745\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5197\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5760\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5682\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5312\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5198\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5267\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5681\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5572\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5834\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5411\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5179\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5248\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5313\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5487\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5325\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5252\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.4792\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 16.6573 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 16.2417 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 15.5076 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.7947 - accuracy: 0.1208 \n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4442\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4435\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4705\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4484\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4301\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5071\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4985\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4523\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4489\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4483\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4793\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4919\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4574\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4634\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4716\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4518\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0794 - accuracy: 0.4490\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.9808 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.5372 - accuracy: 0.3556\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2740 - accuracy: 0.5437\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.9622 - accuracy: 0.4751\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.5275 - accuracy: 0.4886\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5506 - accuracy: 0.5329\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4994\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5381\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5112\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4856\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4803\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4604\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4853\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4920\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4849\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4582\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4983\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4710\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4821\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4990\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.3878\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.0072 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.3894 - accuracy: 0.2530\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.8086 - accuracy: 0.4744\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.1979 - accuracy: 0.4308\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.2431 - accuracy: 0.4665\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.3395 - accuracy: 0.4162\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.7922 - accuracy: 0.4608\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4950\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4554\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4095\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4769\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4598\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4248\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4729\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4646\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4806\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4601\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4501\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4472\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4869\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4792\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.8547 - accuracy: 0.0854 \n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.8421 - accuracy: 0.4942\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.3780 - accuracy: 0.4265\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4370\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4790\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4657\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4544\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4268\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4716\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4549\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4781\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4700\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4574\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4805\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4093\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4477\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4283\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4911\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4400\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4440\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c77c3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3395 - accuracy: 0.5130\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9835 - accuracy: 0.5624\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8352 - accuracy: 0.5256\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.5106\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5651\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5442\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5743\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5654\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5234\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5327\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.4913\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.5568\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.5630\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5312\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5417\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5407\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5470\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.4994\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5773\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5721\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c24d7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.4792\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.1379 - accuracy: 0.5013\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2050 - accuracy: 0.5401\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.7999 - accuracy: 0.5488\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.4552 - accuracy: 0.4861\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.9348 - accuracy: 0.4492\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.6108 - accuracy: 0.4471\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.8110 - accuracy: 0.4407\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2155 - accuracy: 0.4851\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.9997 - accuracy: 0.5005\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.0218 - accuracy: 0.4981\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.4730 - accuracy: 0.5363\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.1296 - accuracy: 0.4879\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.2013 - accuracy: 0.4812\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.5478 - accuracy: 0.4543\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.0407 - accuracy: 0.4888\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.8453 - accuracy: 0.4277\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.1391 - accuracy: 0.4762\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.7985 - accuracy: 0.4978\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.7745 - accuracy: 0.4952\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.5652 - accuracy: 0.4300\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.3334 - accuracy: 0.5144\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.5017 - accuracy: 0.4874\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.4792 - accuracy: 0.4865\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4922\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5279\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4551\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4501\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4910\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4367\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4831\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c807c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4490\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.8111 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.6184 - accuracy: 0.3871\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.9154 - accuracy: 0.4912\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.3996 - accuracy: 0.4476\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.4182 - accuracy: 0.4984\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.3186 - accuracy: 0.4909\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.9878 - accuracy: 0.5044\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.9413 - accuracy: 0.5073\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.1624 - accuracy: 0.4936\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.0737 - accuracy: 0.4991\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.9905 - accuracy: 0.5043\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.2184 - accuracy: 0.4901\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.7346 - accuracy: 0.5201\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.3838 - accuracy: 0.5419\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.4534 - accuracy: 0.5376\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.1883 - accuracy: 0.4920\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.7972 - accuracy: 0.5162\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.8894 - accuracy: 0.5105\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.7036 - accuracy: 0.5221\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.6540 - accuracy: 0.5251\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.7300 - accuracy: 0.5204\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.7835 - accuracy: 0.5171\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.5868 - accuracy: 0.5293\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.8457 - accuracy: 0.5132\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.8844 - accuracy: 0.5108\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.9037 - accuracy: 0.5096\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.2641 - accuracy: 0.5493\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.8063 - accuracy: 0.5157\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.2253 - accuracy: 0.4897\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.5169 - accuracy: 0.5336\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c6ea72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 6.2499 - accuracy: 0.6122\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.7427 - accuracy: 0.0747\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.4716 - accuracy: 0.5299\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.5448 - accuracy: 0.5655\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.3298 - accuracy: 0.5546\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4730\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1008 - accuracy: 0.3361\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4577\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4423\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4405\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4961\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4414\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4590\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4697\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4263\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4933\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4173\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4917\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4361\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4852\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5108\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4617\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4800\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4921\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4588\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4479\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5219\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4820\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4498\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4384\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4528\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87d952f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4792\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.9338 - accuracy: 0.4758\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.7798 - accuracy: 0.4676\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.6358 - accuracy: 0.4415\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.7341 - accuracy: 0.4604\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1878 - accuracy: 0.3512\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4824\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4933\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4693\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4406\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4197\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4536\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4436\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4603\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4998\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4427\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4229\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4835\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4568\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4180\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4438\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4538\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4806\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4857\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4565\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4934\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5028\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4829\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4731\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4433\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4008\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cab8dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 13.7951 - accuracy: 0.0234\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4563\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4456\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4656\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4356\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4426\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4574\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4895\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4087\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4544\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4435\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4769\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4709\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4337\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4212\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4451\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4814\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4603\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4515\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4558\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4566\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4531\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4363\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4724\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4445\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4840\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5111\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4656\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4574\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4856\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c5bda6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.4091 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7848 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5603 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2817 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1924 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1453 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1240 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1117 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1003 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c7789840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.5872 - accuracy: 0.1042\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.9534 - accuracy: 0.5320\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.4403 - accuracy: 0.4730\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.6029 - accuracy: 0.5034\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.8752 - accuracy: 0.4630\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8348 - accuracy: 0.5139\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.9723 - accuracy: 0.3114\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5097\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4751\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5044\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4761\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4546\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5246\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5100\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5135\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5267\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4509\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5254\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5013\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4569\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4983\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4913\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5292\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5041\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5012\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4866\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4274\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4741\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5004\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4696\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5084\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4537\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4993\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5070\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5032\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5095\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4860\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5258\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5062\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5413\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4964\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5100\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4930\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4828\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5132\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4644\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5072\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5230\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5118\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4683\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c49892f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.3878\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 16.2188 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 15.6718 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 15.0613 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.5906 - accuracy: 0.1153\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4448\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4580\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4831\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4889\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4356\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5001\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5140\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4265\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4747\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4454\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4464\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4427\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4707\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4490\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4183\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4714\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4273\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4804\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4553\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4706\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4505\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4310\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4865\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4860\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4551\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4527\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4676\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4055\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4775\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4314\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.5007\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4487\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4150\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4558\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.3705\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5031\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4707\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.3868\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4538\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4459\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4990\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4715\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4461\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4474\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4553\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4525\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c6ea7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4792\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 10.7165 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.8746 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.4700 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.1555 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.7042 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.0665 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.1810 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.1763 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.8845 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.4931 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.5618 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.1036 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.7123 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.1711 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.3039 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.3961 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.4346 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.0234 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.7211 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.8956 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.9082 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.5942 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.6523 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.9984 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.8726 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.0840 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.0601 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.0525 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.4061 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.1300 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.6009 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.0095 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.2148 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.8742 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.1319 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.6503 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.2320 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.9156 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.5812 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.7897 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.5051 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.7074 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.4732 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.5374 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.3445 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.6533 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.9983 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 10.0637 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.7213 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c5c15268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 8.8219 - accuracy: 0.0000e+00\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.0751 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.1181 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9011 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7471 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6453 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5833 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5399 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4505 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3975 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3116 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3162 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2745 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2672 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2416 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2133 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1932 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1928 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1662 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1620 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1357 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1420 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1256 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1129 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1065 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1005 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c90b0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.0000e+00\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.8376 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.6955 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.5824 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.5147 - accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.4334 - accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.3340 - accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.1762 - accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.9730 - accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.8128 - accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.6290 - accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.3787 - accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.0193 - accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.3689 - accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.2240 - accuracy: 0.1637 \n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2592 - accuracy: 0.4294\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4676\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5214\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4631\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4776\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5040\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c5365510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0794 - accuracy: 0.4490\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.8903 - accuracy: 0.2591 \n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4957\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4596\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4773\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4443\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4644\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4773\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4735\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5120\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4780\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4582\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4925\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4891\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5033\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5116\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5165\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4679\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4898\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4818\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4901\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c6ec7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.3878\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 16.2475 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.1138 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.0218 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.8491 - accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.6115 - accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 15.2692 - accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.6789 - accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.2969 - accuracy: 0.0837\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4685\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4633\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4352\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4848\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4439\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5088\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4706\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4446\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4418\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4567\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4633\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4598\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c258ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0794 - accuracy: 0.4792\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 10.3302 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 10.7886 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.2088 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 10.3808 - accuracy: 0.2882\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.5422 - accuracy: 0.4769\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.8178 - accuracy: 0.4501\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.6626 - accuracy: 0.4498\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.7576 - accuracy: 0.4946\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.3144 - accuracy: 0.4481\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.3450 - accuracy: 0.4967\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.4513 - accuracy: 0.4814\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.1338 - accuracy: 0.4883\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.9433 - accuracy: 0.4883\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.2618 - accuracy: 0.4592\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.2928 - accuracy: 0.4418\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.5035 - accuracy: 0.4588\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.4195 - accuracy: 0.4388\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4415\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1369 - accuracy: 0.4703\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4519\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c808f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 16.6872 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.1233 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.0399 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2246 - accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.8278 - accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.6414 - accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.5089 - accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.4066 - accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.3279 - accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2758 - accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2202 - accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.1672 - accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1221 - accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0736 - accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0663 - accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0421 - accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0365 - accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0332 - accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0276 - accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0031 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cabad840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9700 - accuracy: 0.0000e+00\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 9.1152 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.1425 - accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 8.5023 - accuracy: 0.4964\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.4723 - accuracy: 0.4790\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.6244 - accuracy: 0.5145\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.0933 - accuracy: 0.4669\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.1587 - accuracy: 0.4537\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.4105 - accuracy: 0.4860\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 5.8339 - accuracy: 0.4926\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4495\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4631\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4856\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4731\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4686\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4738\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4780\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4693\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4999\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4888\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4676\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4839\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4579\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4839\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4631\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4335\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4676\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4339\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5030\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4763\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4589\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cabc27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4490\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 9.0888 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.7301 - accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.8288 - accuracy: 0.4946\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.9466 - accuracy: 0.4804\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.1042 - accuracy: 0.5252\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.5617 - accuracy: 0.4870\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.9259 - accuracy: 0.4554\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.4110 - accuracy: 0.4759\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.2118 - accuracy: 0.4710\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.6240 - accuracy: 0.4991\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.2532 - accuracy: 0.5103\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.0156 - accuracy: 0.4957\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5009\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4512\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5037\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5099\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4644\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4898\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4877\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4821\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4894\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5009\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4919\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5165\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4894\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4648\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4682\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4932\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4561\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4592\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c6df1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.3878\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 9.7783 - accuracy: 0.4508\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.0648 - accuracy: 0.4859\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.6515 - accuracy: 0.5011\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.0223 - accuracy: 0.4661\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.2010 - accuracy: 0.4442\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.3619 - accuracy: 0.4890\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.7574 - accuracy: 0.4550\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.7664 - accuracy: 0.4407\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.0994 - accuracy: 0.4730\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.5896 - accuracy: 0.4970\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2392 - accuracy: 0.5050\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.0319 - accuracy: 0.4786\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4612\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4675\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4734\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4650\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4869\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5261\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4959\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4890\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4671\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4550\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4817\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4758\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4907\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4348\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4584\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4786\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4577\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4675\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87ece32620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4792\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 16.2354 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.9609 - accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.6502 - accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.2140 - accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.4822 - accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 12.4096 - accuracy: 0.0361\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4522\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4602\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5085\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4526\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4585\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4665\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4616\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4463\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4335\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4793\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4470\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4554\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4498\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.3911\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4710\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4557\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4411\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4623\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4797\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4918\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4710\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4494\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4453\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4557\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c258ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 9.7433 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.7073 - accuracy: 0.0172\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.8563 - accuracy: 0.4939\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.9133 - accuracy: 0.4661\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0169 - accuracy: 0.4904\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6972 - accuracy: 0.4727\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5499 - accuracy: 0.4481\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4023 - accuracy: 0.4470\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2284 - accuracy: 0.4758\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1919 - accuracy: 0.4401\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0732 - accuracy: 0.4585\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9871 - accuracy: 0.4418\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8526 - accuracy: 0.4644\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8141 - accuracy: 0.4599\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7824 - accuracy: 0.4442\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7216 - accuracy: 0.4807\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7000 - accuracy: 0.4724\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.5203\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5506\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.5252\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5155\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.5342\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5224\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5297\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5561\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.5012\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.5155\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5575\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5575\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5790\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c65b31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7038 - accuracy: 0.4792\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 16.1622 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.8403 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 15.4038 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 14.9074 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 14.3711 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 11.2601 - accuracy: 0.0792\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4995\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.0794 - accuracy: 0.4815\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4888\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.0794 - accuracy: 0.4815\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4905\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4770\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4825\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4901\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4752\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4842\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4415\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4960\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4842\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4634\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4742\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5085\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5030\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4849\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4634\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4763\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4645\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4947\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4763\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4710\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4631\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4891\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4634\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4804\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4384\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4881\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4877\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4690\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4697\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.5009\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4776\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4822\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4547\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4516\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4551\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4606\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4856\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4943\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4794\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4770\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c3817a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4490\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 9.1296 - accuracy: 0.0311\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.6054 - accuracy: 0.5022\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5034 - accuracy: 0.5359\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6761 - accuracy: 0.5203\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3482 - accuracy: 0.5061\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0965 - accuracy: 0.5401\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0760 - accuracy: 0.4741\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9031 - accuracy: 0.5311\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8211 - accuracy: 0.5193\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 0.5161\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.5259\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.5397\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.5036\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.5081\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.4956\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5026\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.4891\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.4856\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5023\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4891\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.5539\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4904\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5043\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5168\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5238\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5262\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.4957\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6921 - accuracy: 0.5352\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6925 - accuracy: 0.5064\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.4956\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.5161\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5147\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.4967\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.5081\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.4963\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.4963\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.5047\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.4783\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.4911\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.5307\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5120\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.4838\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.5397\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5147\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.4457\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5327\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5171\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5015\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5123\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c38170d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.6122\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 3.5649 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0033 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8416 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7430 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6768 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6433 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5878 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6001 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5876 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5650 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5243 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4490 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.4603 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4354 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4927 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4413 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4327 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4281 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4160 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4037 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3753 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.3602 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3402 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3515 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3452 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.3323 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3128 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3247 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3098 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3193 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2949 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2495 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3004 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2638 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2571 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2265 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2220 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2357 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2245 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2230 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2084 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2227 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2122 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2149 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1959 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1947 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1905 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1767 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1736 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c656d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1680 - accuracy: 0.0000e+00\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 16.3185 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.1310 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.9276 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.6575 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 15.3333 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.9553 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 14.2632 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.0016 - accuracy: 0.1529 \n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4529\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4470\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4602\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1213 - accuracy: 0.4453\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.8857 - accuracy: 0.3207\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4738\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4581\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4390\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4689\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4519\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4467\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4317\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4415\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4529\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4567\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4352\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4599\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4699\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4602\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4689\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4804\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4453\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4640\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4828\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4560\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4432\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4279\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4810\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4491\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4831\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4533\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4255\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4231\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4189\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4383\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4442\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4581\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4633\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4772\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4498\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4380\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4481\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c0c91e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 6ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 8.1227 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.1934 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.7417 - accuracy: 0.3147\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.5164 - accuracy: 0.5624\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.7458 - accuracy: 0.5391\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.1343 - accuracy: 0.5054\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.6525 - accuracy: 0.5259\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.8044 - accuracy: 0.5710\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9514 - accuracy: 0.5589\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2928 - accuracy: 0.5346\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.5260 - accuracy: 0.5155\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 6.9329 - accuracy: 0.5478\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.7718 - accuracy: 0.5495\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.5598 - accuracy: 0.5478\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 5.8574 - accuracy: 0.4927\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4439\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4706\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4481\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4772\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4942\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4762\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4821\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4241\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4321\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4751\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4394\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4800\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4790\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4748\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4463\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4467\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4130\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4578\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4606\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4592\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4474\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4724\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4692\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4397\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4543\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4783\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.4470\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4206\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4845\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4755\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4692\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4956\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0794 - accuracy: 0.4508\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4557\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4574\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c7799ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0794 - accuracy: 0.5208\n",
            "Epoch 1/30\n",
            "13/13 [==============================] - 1s 2ms/step - loss: 8.5879 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.0456 - accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.2187 - accuracy: 0.3659\n",
            "Epoch 4/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9748 - accuracy: 0.4588\n",
            "Epoch 5/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.7077 - accuracy: 0.5080\n",
            "Epoch 6/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.5052 - accuracy: 0.5537\n",
            "Epoch 7/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4502\n",
            "Epoch 8/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.1236 - accuracy: 0.4625\n",
            "Epoch 9/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4758\n",
            "Epoch 10/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5058\n",
            "Epoch 11/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4875\n",
            "Epoch 12/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4978\n",
            "Epoch 13/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4810\n",
            "Epoch 14/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4578\n",
            "Epoch 15/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4964\n",
            "Epoch 16/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4824\n",
            "Epoch 17/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4762\n",
            "Epoch 18/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4920\n",
            "Epoch 19/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4948\n",
            "Epoch 20/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4842\n",
            "Epoch 21/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4267\n",
            "Epoch 22/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4573\n",
            "Epoch 23/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4831\n",
            "Epoch 24/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4653\n",
            "Epoch 25/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4152\n",
            "Epoch 26/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4767\n",
            "Epoch 27/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4374\n",
            "Epoch 28/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.4387\n",
            "Epoch 29/30\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4457\n",
            "Epoch 30/30\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0794 - accuracy: 0.5116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZW33uQ5_SLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1117f74b-2e85-4735-d5fd-d58e8b7b8013"
      },
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.516411554813385 using {'batch_size': 20, 'epochs': 30}\n",
            "Means: 0.46726189851760863, Stdev: 0.037363706367378215 with: {'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.4919217526912689, Stdev: 0.056881965056700415 with: {'batch_size': 10, 'epochs': 30}\n",
            "Means: 0.46318026185035704, Stdev: 0.04410355731057997 with: {'batch_size': 10, 'epochs': 50}\n",
            "Means: 0.46318026185035704, Stdev: 0.04410355731057997 with: {'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.516411554813385, Stdev: 0.05505885492008089 with: {'batch_size': 20, 'epochs': 30}\n",
            "Means: 0.1733843505382538, Stdev: 0.21431007176908232 with: {'batch_size': 20, 'epochs': 50}\n",
            "Means: 0.3673469305038452, Stdev: 0.18872512922174514 with: {'batch_size': 40, 'epochs': 20}\n",
            "Means: 0.46318026185035704, Stdev: 0.04410355731057997 with: {'batch_size': 40, 'epochs': 30}\n",
            "Means: 0.4205782234668732, Stdev: 0.21657837475261815 with: {'batch_size': 40, 'epochs': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}